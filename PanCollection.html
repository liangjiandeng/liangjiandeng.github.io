<html lang="en"><head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>PanCollection for Survey Paper</title>


    <!-- Custom CSS -->
    <style>
    body {
        padding-top: 20px;
        /* Required padding for .navbar-fixed-top. Remove if using .navbar-static-top. Change if height of navigation changes. */
    }
    .STYLE1 {font-size: 18px}
    .STYLE2 {font-size: 14px}
    #Layer1 {
	position:absolute;
	left:105px;
	top:232px;
	width:1449px;
	height:226px;
	z-index:1;
}
    #Layer2 {
	position:absolute;
	left:105px;
	top:459px;
	width:1450px;
	height:266px;
	z-index:2;
}
    .STYLE3 {
	font-size: 16px;
        font-weight:normal;
}
    </style>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

        <script type="text/javascript" async="" src="http://www.google-analytics.com/ga.js"></script><script type="text/javascript">
            
            var _gaq = _gaq || [];
            _gaq.push(['_setAccount', 'UA-22940424-1']);
            _gaq.push(['_trackPageview']);
            
            (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
            })();
            
        </script>    
</head>

<p><span class="style8"><font face="Arial">
<a href="../index.html" style="color: blue"><font size="4" face="Arial">< Home</font></a> &nbsp;&nbsp;&nbsp;&nbsp;
<a href="../Projects_Res.html" style="color: blue"><font size="4" face="Arial">< Project Home</font></a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</font></span></p>
	
<!------------------------------------------------------------------------------------- ------>   
<!---------------------------------MAIN Body---------------------------------------------------- ------>   
<!------------------------------------------------------------------------------------- ------>   
<body data-gr-c-s-loaded="true">

    <!-- Navigation -->
    <!-- Page Content -->
    <div class="container">

        <div class="row">
            <div class="col-lg-12 text-center">
<!---------------------------------Title---------------------------------------------------- ------>   
                <h1 align="center">PanCollection</h1>
<!---------------------------------Authors---------------------------------------------------- ------>   
              <p align="center" class="lead STYLE1"><strong>Liang-Jian Deng</strong></p>           
				<p align="center" class="lead"><strong>     </strong></p>
				<h2 align="center" style="text-align:centre">&nbsp;</h2>

    
<!---------------------------------Abstract---------------------------------------------------- ------>   
				<h2 align="center" style="text-align:centre">Abstract</h2>
				  <font style="font-size: 13pt;" face="Arial">
				      <p> Pansharpening refers to a spatio-spectral fusion of a lower spatial resolution multispectral image with a 
                  high spatial resolution panchromatic image, aiming at obtaining an image with a corresponding high resolution both in the domains. In this paper, 
                             we propose a generic fusion framework that is able to weightedly combine variational optimization (VO) with deep learning (DL) for the task of 
                             pansharpening, where these crucial weights directly determining the relative contribution of DL to each pixel are estimated adaptively. This 
                             framework can benefit from both VO and DL approaches, e.g., the good modeling explanation and data generalization of a VO approach with the
                             high accuracy of a DL technique thanks to massive data training. The proposed method can be divided into three parts: i) For the VO modeling, 
                             a general details injection term inspired by the classical multi-resolution analysis is proposed as a spatial fidelity term and a spectral
                             fidelity employing the multispectral sensor’s modulation transfer functions is also incorporated; ii) For the DL injection, a weighted 
                             regularization term is designed to introduce deep learning into the variational model; iii) The final convex optimization problem is efficiently 
                             solved by the designed alternating direction method of multipliers. Extensive experiments both at reduced and full resolution demonstrate that the 
                             proposed method outperforms recent state-of-the-art pansharpening methods, especially showing a higher accuracy and a significant generalization 
                             ability. 
</h4>
<br><br>
		    
<!---------------------------------PanCollection Dataset---------------------------------------------------- ------>   	    
<table class="imgtable"><tr><td>
<img src="teaching/Math_Exp/matlab.jpg" alt="" width="200px" /> </td>
<td align="left"><p>
<ul>
<li><font size="5" color="blue" font-weight:bold face="Arial">PanCollection Dataset </font>
<span lang="zh-cn"><font style="font-size: 14pt;" face="楷体">(PanCollection数据集)</span></font> <br> 
<br>
<li><font size="4" color="red" face="Arial">WV3 Dataset</font> <br> 
<span lang="zh-cn"><font style="font-size: 12pt;" face="楷体">[1] Training Dataset(训练数据集)：</span></font>
<a href="teaching/Math_Exp/Project1_Signal_Rec_ADMM.zip" style="color: blue">[Project1_Signal_Rec_ADMM]</a><br> 
<span lang="zh-cn"><font style="font-size: 12pt;" face="楷体">[2] Testing Dataset(测试数据集)：</span></font>
<a href="teaching/Math_Exp/Project2_K_Means_ToStudent.zip" style="color: blue">[Project2_K_Means_ToStudent]</a><br> 
<br>
</li>
<li><font size="4" color="red" face="Arial">QB Dataset</font> <br> 
<span lang="zh-cn"><font style="font-size: 12pt;" face="楷体">[1] Training Dataset(训练数据集)：</span></font>
<a href="teaching/Math_Exp/Project1_Signal_Rec_ADMM.zip" style="color: blue">[Project1_Signal_Rec_ADMM]</a><br> 
<span lang="zh-cn"><font style="font-size: 12pt;" face="楷体">[2] Testing Dataset(测试数据集)：</span></font>
<a href="teaching/Math_Exp/Project2_K_Means_ToStudent.zip" style="color: blue">[Project2_K_Means_ToStudent]</a><br> 
<br>
</li>
<li><font size="4" color="red" face="Arial">GF2 Dataset</font> <br> 
<span lang="zh-cn"><font style="font-size: 12pt;" face="楷体">[1] Training Dataset(训练数据集)：</span></font>
<a href="teaching/Math_Exp/Project1_Signal_Rec_ADMM.zip" style="color: blue">[Project1_Signal_Rec_ADMM]</a><br> 
<span lang="zh-cn"><font style="font-size: 12pt;" face="楷体">[2] Testing Dataset(测试数据集)：</span></font>
<a href="teaching/Math_Exp/Project2_K_Means_ToStudent.zip" style="color: blue">[Project2_K_Means_ToStudent]</a><br> 
<br>
</li>
<li><font size="4" color="red" face="Arial">WV2 Dataset</font> <br> 
<span lang="zh-cn"><font style="font-size: 12pt;" face="楷体">[2] Testing Dataset (测试数据集)：</span></font>
<a href="teaching/Math_Exp/Project2_K_Means_ToStudent.zip" style="color: blue">[Project2_K_Means_ToStudent]</a><br> 
<br>
</li>
</ul>
</td></tr></table>
		    
		    
		    
		    
		    
<!---------------------------------Uniformed Pytorch Codes Framework ---------------------------------------------------- ------>   	    
<table class="imgtable"><tr><td>
<img src="teaching/Math_Exp/matlab.jpg" alt="" width="200px" /> </td>
<td align="left"><p>
<ul>
<li><font size="5" color="blue" font-weight:bold face="Arial">Uniformed Pytorch Codes Framework</font>
<span lang="zh-cn"><font style="font-size: 14pt;" face="楷体">(统一的Pytorch代码框架)</span></font> <br> 
<br>
</li>
<li><font size="4" color="red" face="Arial">Download via GitHub Page</font> <br> 
<span lang="zh-cn"><font style="font-size: 12pt;" face="楷体"> [1] Download Link(下载链接)：</span></font>
<a href="teaching/Math_Exp/Project1_Signal_Rec_ADMM.zip" style="color: blue">[Project1_Signal_Rec_ADMM]</a><br> 
<span lang="zh-cn"><font style="font-size: 12pt;" face="楷体">[2] One example to illustrate details(一个此Pytorch代码框架的简单示例，推荐通过此学习)：</span></font>
<a href="teaching/Math_Exp/Project2_K_Means_ToStudent.zip" style="color: blue">[Project2_K_Means_ToStudent]</a><br> 
<br>
</li>
</ul>
</td></tr></table>	    
		    
		    
		
<!---------------------------------Traditional-DL Matlab Testing Package ---------------------------------------------------- ------>   	    
<table class="imgtable"><tr><td>
<img src="teaching/Math_Exp/matlab.jpg" alt="" width="200px" /> </td>
<td align="left"><p>
<ul>
<li><font size="5" color="blue" font-weight:bold face="Arial">Matlab Testing Package for Traditional and DL-based Pansharpening Methods</font>
<span lang="zh-cn"><font style="font-size: 14pt;" face="楷体">(传统方法-深度学习方法测试MATLAB软件包)</span></font> <br> 
<br>
</li>
<li><font size="4" color="red" face="Arial">Download via GitHub Page</font> <br> 
<span lang="zh-cn"><font style="font-size: 12pt;" face="楷体"> [1] Download Link(下载链接)：</span></font>
<a href="teaching/Math_Exp/Project1_Signal_Rec_ADMM.zip" style="color: blue">[Project1_Signal_Rec_ADMM]</a><br> 
<span lang="zh-cn"><font style="font-size: 12pt;" face="楷体">[2] One example to illustrate details(一个简单使用示例，推荐通过此学习)：</span></font>
<a href="teaching/Math_Exp/Project2_K_Means_ToStudent.zip" style="color: blue">[Project2_K_Means_ToStudent]</a><br> 
<br>
</li>
</ul>
</td></tr></table>	
		    
		    
		    
		    
<!---------------------------------Citation---------------------------------------------------- ------>   
	  <div class="row" >
		<blockquote>
		  <h2 style="color: blue" style="text-align:left">Bib Citation</h2>
	          <font style="font-size: 10pt;" face="Arial">

@ARTICLE{Wu2021VO, <br>
author={Z. C. Wu and T. Z. Huang and L. J. Deng and J. F. Hu and G. Vivone},  <br>
journal={IEEE Transactions on Geoscience and Remote Sensing},   <br>
title={VO+Net: An Adaptive Approach Using Variational Optimization and Deep Learning for Panchromatic Sharpening},  <br>
year={2021},  <br>
volume={},  <br>
number={},  <br>
pages={1-16},  <br>
doi={10.1109/TGRS.2021.3066425},<br>
}<br>
			}<br>
	  </div>
    <br>	
		<br>	    
		    


    <!-- /.container -->

    <!-- jQuery Version 1.11.0 -->
    <!-- <script src="FSRCNN/js/jquery-1.11.0.js"></script>-->

    <!-- Bootstrap Core JavaScript -->
    <!--<script src="FSRCNN/js/bootstrap.min.js"></script>-->




</body></html>
